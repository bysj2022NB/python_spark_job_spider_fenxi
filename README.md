## Python+Spark招聘爬虫可视化系统 招聘数据分析 Hadoop职位可视化 大数据毕业设计 51job数据分析 Scrapy招聘爬虫(可选加推荐算法)

## 要求
### 源码800一套不议价(论文 PPT 源码+sql脚本)
### 白嫖滚蛋！源码收费的！别怨repo主爆粗口只是每天被一群白嫖杂种整神经了
### 加好友前帮忙start一下，并备注github有偿获取源码
### 我的QQ号是2877135669 或者 1679232425
### 加qq好友说明（被部分 s b 网友整得心力交瘁）：
    1.加好友务必按照格式备注
    2.避免浪费各自的时间，不议价！不议价！不议价！
    3.当“客服”不容易，repo 主是体面人，不爆粗，性格好，文明人。上面的 sb 字眼请谅解

## 为啥这么娼？
全网做Python+Spark的爬虫分析可视化我是唯一一家，另外我的运行简单操作简单，不用搞一堆集群崩溃
另外大数据毕业设计这块我们也是业界第一   

另外实话告诉你招聘爬虫现在可多接口全死了，你要觉得你自己挺厉害，请绕行别找我！

## 开发技术
Hadoop、HDFS、Spark、SpringBoot、echarts、PySpark、Python、MySQL

## 创新点
大数据架构、爬虫、数据可视化



## 补充说明
适合大数据毕业设计、数据分析、爬虫类计算机毕业设计

可二次开发选加推荐算法(协同过滤算法等或者调用SparkML库)

![](/项目包含全部资料截图.png)





## 数据处理流程
本环节主要讲述的是对于整体项目功能的设计，设计方案为主要是由大数据系统以及可视化前端子系统组成。
在可视化前端子系统中主要是采用了Springboot框架，mybatis框架，因为其去繁就简的特点，
很容易创建一个独立的产品级应用，在可视化阶段采用Echarts来提供可交互的直观数据可视化图表。
本系统采用的数据库是MySQL数据库，
其目的是用来存储利用爬虫爬取到的大量招聘信息数据集和数据处理之后的分析结果。
大数据系统中主要是对招聘信息数据集通过使用Hive进行数据清洗，
然后再导入Hadoop HDFS中分布存储。在通过Spark并行计算进行数据抽取，多维分析，
查询统计等操作来完成数据分析部分。
在前端子系统中的数据明细查询功能中读取到MySQL数据库中的数据分析结果，
最后生成Echarts图表展示给用户，大数据招聘信息智能分析平台的工作流程如下图所示。

![](/基于Spark职位分析系统-流程图.jpg)





# 运行截图

![](/QQ截图20211127023053.png)





![图片1](/图片1.png)

![](/QQ截图20211127023125.png)

![](/QQ截图20211127023138.png)

# 运行视频(B站)

https://www.bilibili.com/video/BV1VP4y1V7vy?spm_id_from=333.999.0.0





